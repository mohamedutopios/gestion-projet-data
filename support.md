---
marp: true
title: Gestion projet Big Data
theme: utopios
paginate: true
author: Mohamed Aijjou
header: "![h:70px](https://utopios-marp-assets.s3.eu-west-3.amazonaws.com/logo_blanc.svg)"
footer: "Utopios¬Æ Tous droits r√©serv√©s"
---

<!-- _class: lead -->
<!-- _paginate: false -->

# Big Data ‚Äì Concevoir et piloter un projet

---

## Sommaire

1. Fondamentaux et cadrage strat√©gique
2. Architecture et conception
3. Pilotage et gouvernance
4. R√©union projet et mise en pratique

</div>

---

<!-- _class: lead -->
<!-- _paginate: false -->

## Fondamentaux et cadrage strat√©gique

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data

<br/>

<div style="font-size:39px">

Un projet Big Data ne s‚Äôimprovise pas : il doit suivre un **cycle m√©thodologique pr√©cis** qui combine **besoins m√©tiers, faisabilit√© technique, gestion des donn√©es et pilotage √©conomique**.

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:24px">


## 1Ô∏è‚É£ Expression du besoin m√©tier

Avant toute consid√©ration technologique, il faut **clarifier les objectifs m√©tiers** :
Le projet doit r√©pondre √† une **probl√©matique concr√®te** et non √† une mode technologique.

### üîπ Points cl√©s

* Identifier les **cas d‚Äôusage prioritaires** : marketing, finance, logistique, production, sant√©‚Ä¶
* D√©finir les **indicateurs de performance (KPI)** attendus : r√©duction des co√ªts, augmentation des ventes, rapidit√© de traitement, taux de satisfaction client.
* Identifier les **utilisateurs finaux** : analystes, managers, √©quipes op√©rationnelles.
* Clarifier les **contraintes m√©tiers** : confidentialit√©, temps r√©el, pr√©cision des r√©sultats.

</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:28px">


### üîπ Exemples

* Un distributeur veut r√©duire de 20 % ses ruptures de stock via l‚Äôanalyse pr√©dictive de la demande.
* Une banque veut d√©tecter les fraudes en temps r√©el et diminuer les pertes de 15 %.
* Un h√¥pital veut optimiser l‚Äôoccupation des lits et r√©duire le temps d‚Äôattente moyen aux urgences.

üëâ **Livrable** : Cahier des charges fonctionnel d√©crivant besoins, objectifs et KPI.

</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:22px">

## 2Ô∏è‚É£ √âtude de faisabilit√© et cadrage technique

Une fois le besoin d√©fini, il faut v√©rifier **si le projet est r√©alisable** techniquement et organisationnellement.

### üîπ √âtapes de cadrage

1. **Analyse des syst√®mes existants** : infrastructures, bases de donn√©es, outils BI d√©j√† en place.
2. **Identification des contraintes techniques** :

   * Volumes de donn√©es √† traiter (Go, To, Po).
   * N√©cessit√© de temps r√©el (streaming) ou batch.
   * Compatibilit√© avec syst√®mes existants.


</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:26px">

## 2Ô∏è‚É£ √âtude de faisabilit√© et cadrage technique

3. **Choix d‚Äôune approche technologique** (sans figer trop t√¥t) :

   * Hadoop vs Spark vs Cloud.
   * Data Lake vs Data Warehouse vs hybride.
   * NoSQL vs SQL.
4. **√âvaluation organisationnelle** : comp√©tences disponibles (data engineer, data scientist, architecte), besoin de formation ou de recrutement.


</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:24px">

## 2Ô∏è‚É£ √âtude de faisabilit√© et cadrage technique

### üîπ M√©thodes

* **POC (Proof of Concept)** : prototype limit√© pour tester faisabilit√©.
* **Pilote** : d√©ploiement sur un p√©rim√®tre restreint avant g√©n√©ralisation.

### üîπ Exemple

* Une compagnie a√©rienne lance un POC avec Spark Streaming pour analyser les donn√©es moteurs en temps r√©el avant un d√©ploiement global.

üëâ **Livrable** : Document de cadrage technique (solutions envisag√©es, contraintes, premiers choix d‚Äôarchitecture).


</div>

---

### Fondamentaux et cadrage strat√©gique

#### √âtapes d‚Äôun projet Big Data


<div style="font-size:21px">

## 3Ô∏è‚É£ Identification des donn√©es disponibles et manquantes

Le **c≈ìur du Big Data** est la donn√©e elle-m√™me : il faut identifier ce qui existe, ce qui est manquant et la qualit√© des sources.

### üîπ √âtapes

1. **Inventaire des donn√©es existantes** : bases internes (ERP, CRM, transactions, logs).
2. **Donn√©es externes** : open data, donn√©es partenaires, r√©seaux sociaux, capteurs IoT.
3. **Analyse de la qualit√© des donn√©es** : coh√©rence, compl√©tude, exactitude, doublons.
4. **Identification des manques** : quelles donn√©es sont n√©cessaires mais absentes ?

   * Exemple : un projet de maintenance pr√©dictive peut n√©cessiter l‚Äôajout de capteurs IoT sur les machines.
5. **Modalit√©s d‚Äôacquisition** : achat, collecte en continu, API, web scraping.


</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:26px">

## 3Ô∏è‚É£ Identification des donn√©es disponibles et manquantes

### üîπ Exemples

* Dans un projet de recommandation e-commerce : donn√©es disponibles = historique d‚Äôachats ; donn√©es manquantes = navigation anonyme des visiteurs ‚Üí besoin de cookies et logs web.
* Dans un projet sant√© : donn√©es existantes = dossiers patients ; donn√©es manquantes = suivi en temps r√©el via objets connect√©s.

üëâ **Livrable** : Cartographie des donn√©es (sources, formats, qualit√©, manquants).


</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:26px">

## 4Ô∏è‚É£ Estimation co√ªts, d√©lais, ROI

Enfin, un projet Big Data doit √™tre √©valu√© sur le plan **√©conomique et temporel** pour arbitrer et valider son lancement.

### üîπ Estimation des co√ªts

* **Infrastructures** : serveurs, cloud, stockage, licences logicielles.
* **D√©veloppement & int√©gration** : POC, pipelines de donn√©es, visualisations.
* **Ressources humaines** : data engineers, data scientists, formation interne.
* **Maintenance & exploitation** : monitoring, s√©curit√©, gouvernance.

</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:28px">

## 4Ô∏è‚É£ Estimation co√ªts, d√©lais, ROI

### üîπ Estimation des d√©lais

* D√©couper le projet en **jalons** : cadrage, POC, pilote, d√©ploiement, industrialisation.
* M√©thodologie Agile (sprints, MVP) ou cycle en V selon l‚Äôorganisation.
* √âvaluer le **time-to-market** n√©cessaire : un projet de d√©tection de fraude doit √™tre op√©rationnel rapidement.


</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:23px">

## 4Ô∏è‚É£ Estimation co√ªts, d√©lais, ROI

### üîπ Mesure du ROI (Return On Investment)

* **ROI quantitatif** :

  * Augmentation du chiffre d‚Äôaffaires (ex. recommandations personnalis√©es).
  * R√©duction des co√ªts (ex. optimisation logistique, maintenance pr√©dictive).
* **ROI qualitatif** :

  * Am√©lioration de la satisfaction client.
  * R√©putation et image de marque (innovation).
  * Meilleure conformit√© r√©glementaire.


</div>

---

## Fondamentaux et cadrage strat√©gique

### √âtapes d‚Äôun projet Big Data


<div style="font-size:26px">

## 4Ô∏è‚É£ Estimation co√ªts, d√©lais, ROI

### üîπ Exemple chiffr√©

* Projet de maintenance pr√©dictive :

  * Co√ªt : 2 M‚Ç¨ (capteurs + d√©veloppement).
  * √âconomies pr√©vues : 5 M‚Ç¨ sur 3 ans (r√©duction pannes et arr√™ts de production).
  * ROI positif en moins de 18 mois.

üëâ **Livrable** : Business case complet (budget, planning, ROI, risques).


</div>

---

### Fondamentaux et cadrage strat√©gique

#### √âtapes d‚Äôun projet Big Data


<div style="font-size:26px">

### Synth√®se visuelle

| √âtape                          | Objectifs                               | Livrables                      |
| ------------------------------ | --------------------------------------- | ------------------------------ |
| Expression du besoin m√©tier    | D√©finir objectifs, KPI, utilisateurs    | Cahier des charges fonctionnel |
| √âtude de faisabilit√© & cadrage | V√©rifier contraintes techniques, tester | Document de cadrage + POC      |
| Identification des donn√©es     | Lister sources, qualit√©, manquants      | Cartographie des donn√©es       |
| Estimation co√ªts/d√©lais/ROI    | Arbitrer lancement, valider financement | Business case complet          |

</div>

---

<!-- _class: lead -->
<!-- _paginate: false -->

## Architecture et conception

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:21px">

## 1) Collecte : batch vs streaming (Kafka, Flume)

### 1.1 D√©cider batch vs streaming

**Crit√®res**

* **Latence cible** : reporting J+1 ‚Üí *batch* ; d√©tection fraude < 2 s ‚Üí *streaming*.
* **Variabilit√© du d√©bit** : pics impr√©visibles ‚Üí *streaming* + backpressure.
* **Co√ªts** : batch = peu de compute en continu ; streaming = compute 24/7.
* **Exactitude** : forte exigence d‚Äôexactement-une-fois ‚Üí *streaming* avec transactions / idempotence.
* **Source** : syst√®mes transactionnels (CDC) ‚Üí *streaming* ; exports planifi√©s ‚Üí *batch*.

**D√©cision rapide**

* **Batch** : charges **ELT/ETL planifi√©es**, recharges historiques, calculs lourds non temps r√©el.
* **Streaming** : **√©v√©nements** (clics, IoT, paiements), **CDC** (Change Data Capture), alerting en temps r√©el.
</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:23px">

## 1) Collecte : batch vs streaming (Kafka, Flume)

### 1.2 Pipeline batch (exemples)

* **Sources** : exports SQL (dump), fichiers S3/Azure Blob/GCS, SFTP, API pagin√©es.
* **Ingestion** : jobs Airflow/Dagster/Prefect, *windowing* temporel, checksum & contr√¥le de volumes.
* **Contrats de donn√©es** : sch√©ma (Avro/JSON), r√®gles de qualit√© en amont, *schema-on-read* au lac.
* **Fiabilit√©** : d√©p√¥ts *landing* immuables, renommage atomique, idempotence (√©criture *overwrite* partitionn√©e).
* **Qualit√©** : Great Expectations/Deequ (compl√©tude, unicit√©, ranges) + *data drift* basique (distribution).
</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:23px">

## 1) Collecte : batch vs streaming (Kafka, Flume)

### 1.3 Pipeline streaming

* **Kafka** (r√©f√©rence industrielle)

  * **Concepts** : *topics*, **partitions** (par cl√©), **consumer groups** (scalabilit√©), **r√©plication**.
  * **S√©mantiques** : *at-least-once* par d√©faut ; **exactly-once** via **transactions** + producteurs idempotents + *read-process-write* atomique.
  * **R√©tention** : temps (ex. 7 jours) ou **log compaction** (derni√®re valeur par cl√©).
  * **Sch√©mas** : **Schema Registry** (Avro/Protobuf/JSON), politiques d‚Äô√©volution (*backward/forward/full*).
  * **CDC** : **Debezium** (MySQL/Postgres/Oracle) ‚Üí topics Kafka (insert/update/delete), *outbox pattern* pour services.
  * **Backpressure & replays** : d√©calages (*offsets*) contr√¥l√©s, *dead-letter topics* pour messages invalides.
* **Flume** (legacy, encore pr√©sent)
</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:22px">

## 2) Stockage : Data Lake vs Data Warehouse vs Lakehouse

### 2.1 Data Lake

* **Support** : objet (S3/ADLS/GCS, HDFS).
* **Formats** : **Parquet/ORC** (colonnaires), **Avro** (row, sch√©ma fort).
* **Zonage (m√©dallion)** :

  * **Bronze/raw** : donn√©es brutes, immuables.
  * **Silver/clean** : normalis√©es, qualit√© appliqu√©e.
  * **Gold/serve** : orient√©es usages (BI/ML), parfois d√©normalis√©es.
* **+** : faible co√ªt, tous formats, id√©al ML/IA & historisation longue.
* **‚Äì** : gouvernance SQL & *concurrency* difficiles sans table format ACID.


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:22px">

## 2) Stockage : Data Lake vs Data Warehouse vs Lakehouse

### 2.1 Data Lake

### Tables ACID sur le lac

* **Delta Lake / Apache Iceberg / Apache Hudi** :

  * **ACID**, *time travel*, **schema evolution**, MERGE/UPSERT, **vacuum/compaction**, *data skipping*.
  * **Choix** :

    * **Delta** : √©cosyst√®me Spark/Dbricks, simple et complet.
    * **Iceberg** : moteur-agnostique (Spark, Flink, Trino, Snowflake), tables √©volu√©es, partitionnement cach√©.
    * **Hudi** : fort sur **UPSERT/CDC** (*Copy-On-Write*, *Merge-On-Read*).


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:25px">

## 2) Stockage : Data Lake vs Data Warehouse vs Lakehouse

## 2.2 Data Warehouse (EDW)

* **MPP SQL** (Snowflake, BigQuery, Redshift, Synapse, Vertica).
* **Mod√©lisation** : **√©toile/flocon**, *conformed dimensions*, SCD (Type 1/2).
* **Patron** : **ELT** (charger brut ‚Üí transformer en SQL dans l‚ÄôEDW, **dbt**).
* **+** : gouvernance SQL robuste, *optimizer*, s√©curit√© fine, **BI** native.
* **‚Äì** : moins adapt√© aux **donn√©es non structur√©es** & workloads ML lourds ; co√ªt selon volum√©trie/scan.


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:27px">

## 2) Stockage : Data Lake vs Data Warehouse vs Lakehouse

## 2.3 Lakehouse

* **Id√©e** : unifier **lac (faible co√ªt, flexibilit√©)** et **entreposage (gouvernance SQL/ACID)** via Delta/Iceberg/Hudi + moteur SQL (Spark SQL/Trino/DuckDB/warehouse natif).
* **Avantages** : **une seule copie** des donn√©es pour BI & ML, *time travel*, gouvernance unifi√©e.
* **Points d‚Äôattention** : tuning partitions, **small files problem** (‚Üí *compaction*, *OPTIMIZE*, *bin packing*), indexation (Z-Order, clustering).


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:21px">

## 2) Stockage : Data Lake vs Data Warehouse vs Lakehouse

### 2.4 Matrice de choix (raccourci)

| Crit√®re          | Data Lake                  | EDW       | Lakehouse            |
| ---------------- | -------------------------- | --------- | -------------------- |
| Types de donn√©es | Tous (struct./non struct.) | Structur√© | Tous                 |
| Co√ªt stockage    | ‚òÖ‚òÖ (bas)                   | ‚òÖ‚òÖ‚òÖ       | ‚òÖ‚òÖ                   |
| BI SQL gouvern√©e | ‚òÖ                          | ‚òÖ‚òÖ‚òÖ       | ‚òÖ‚òÖ‚Äì‚òÖ‚òÖ‚òÖ               |
| ML/IA            | ‚òÖ‚òÖ‚òÖ                        | ‚òÖ‚òÖ        | ‚òÖ‚òÖ‚òÖ                  |
| Upsert/ACID      | (avec Delta/Iceberg/Hudi)  | Natif     | Natif (table format) |
| Time-to-value    | Moyen                      | Rapide    | Rapide               |


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:27px">

## 2) Stockage : Data Lake vs Data Warehouse vs Lakehouse

**Bonnes pratiques stockage**

* **Partitionnement** : champs peu cardinal (date, pays) ; √©viter partitions ultra fines.
* **Taille fichiers** : viser 128‚Äì1024 MB ; planifier **compaction**.
* **Catalog** : Hive Metastore/Glue/Unity/OtterTune-like ; **catalog central** + *data lineage*.
* **S√©curit√©** : RBAC/ABAC, chiffrement KMS, **masquage**/tokenization, *row/column-level security*.

</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:21px">

## 3) Traitement : Spark, MapReduce, ETL

### 3.1 Apache Spark (standard moderne)

* **APIs** : DataFrame/Dataset, **Spark SQL**, **Structured Streaming**.
* **Moteurs** : YARN / **Kubernetes** / Standalone.
* **Pattern** : **ELT/ETL** (batch et micro-batch) + **streaming unifi√©**.
* **Optimisation** :

  * **AQE** (Adaptive Query Execution), **broadcast joins**, *predicate pushdown*, *cache*, *checkpointing*.
  * G√©rer **shuffle** (co√ªt), **numPartitions** coh√©rents, *coalesce/repartition*.
* **Streaming** : fen√™tres tumbling/sliding, **watermarks**, *stateful ops*, *exactly-once* (avec sinks ACID/transactions).
* **Sinks** : Delta/Iceberg/Hudi, Kafka, JDBC, REST, Elasticsearch.

</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:20px">

## 3) Traitement : Spark, MapReduce, ETL

### 3.2 MapReduce (h√©ritage)

* **Usage r√©siduel** : jobs simples, historiques, o√π la latence n‚Äôa aucune importance.
* **Limites** : tr√®s lent (multi-phase disque), difficile √† maintenir ; pr√©f√©rer **Spark/Flink**.

### 3.3 ETL/ELT & orchestration

* **Orchestrateurs** : **Airflow**, **Dagster**, **Prefect** (DAGs, *retry*, SLA, backfills).
* **ELT** : ing√©rer brut ‚Üí **dbt** (transformations SQL versionn√©es, tests, *semantic layer*).
* **Flux** : **NiFi** (flow-based), **Kafka Connect** (connecteurs), **Logstash/Fluent Bit** (logs).
* **Qualit√©/Observabilit√©** : Great Expectations/Deequ, Monte Carlo/Bigeye (SLA, fra√Æcheur, volum√©trie, anomalies).
* **SCD** : Type 1 (√©crasement) / Type 2 (historisation) ‚Üí MERGE sur Delta/Iceberg/Hudi.
* **Tests** : unitaires (UDF), int√©gration (√©chantillons), *data tests* (contrats), *canary runs*.

</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:22px">

## 3) Traitement : Spark, MapReduce, ETL

### 3.2 MapReduce (h√©ritage)

* **Usage r√©siduel** : jobs simples, historiques, o√π la latence n‚Äôa aucune importance.
* **Limites** : tr√®s lent (multi-phase disque), difficile √† maintenir ; pr√©f√©rer **Spark/Flink**.

### 3.3 ETL/ELT & orchestration

**Performance & co√ªts**

* **Small files** : regrouper (**OPTIMIZE**, *compaction jobs*).
* **Skew** : *salting*, *skew join hints*.
* **Cache** : parcimonieux (m√©moire), lib√©rer quand inutile.
* **Autoscaling** : Kubernetes/Serverless (pr√©voir *warm pools* pour streaming).


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:25px">

## 4) Analyse & restitution : BI, ML, IA, dashboards

### 4.1 BI & datamarts

* **Couches Gold** ‚Üí **datamarts** (√©toile/flocon), KPI normalis√©s, glossaire m√©tier.
* **S√©mantique** : mod√®les (Looker/Power BI semantic model, dbt metrics), **RLS/CLS** (row/column-level security).
* **Actualisation** : *scheduled refresh* (batch) vs *DirectQuery/Live* (quasi-temps r√©el).
* **Gouvernance** : *certified datasets*, *data lineage*, tests d‚Äôacceptation m√©tier.


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:22px">

## 4) Analyse & restitution : BI, ML, IA, dashboards

### 4.2 ML & IA

* **Feature pipelines** : jeux **Silver ‚Üí Features Gold**, **feature store** (Feast/Tecton).
* **Entra√Ænement** : Spark MLlib/Sklearn/TensorFlow/PyTorch, **tracking** MLflow (params, m√©triques, artefacts).
* **D√©ploiement** :

  * **Batch scoring** (jobs planifi√©s vers tables *serving*),
  * **Online** (API temps r√©el, Kafka stream processors).
* **MLOps** : registry, **A/B testing**, *shadow mode*, surveillance (d√©rive donn√©es/mod√®les), alertes.
* **Explicabilit√©** : SHAP/LIME, rapports de biais, cartes de chaleur des caract√©ristiques.


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:22px">

## 4) Analyse & restitution : BI, ML, IA, dashboards

## 4.3 Dashboards & apps de donn√©es

* **Design** : temps de chargement < 3 s, **drill-down**, *alerting* (seuils/KPI), annotations d‚Äô√©v√©nements.
* **Caching** : *materialized views*, *result cache*, *aggregations tables*.
* **Distribution** : portail BI, email/PDF programm√©s, **APIs/embeds**, **reverse ETL** (HubSpot, Salesforce, outils op√©rationnels).


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:25px">

## 5) Blueprints d‚Äôarchitecture (r√©f√©rences rapides)

### 5.1 ‚ÄúBatch-first‚Äù (EDW + lac)

1. **Collecte batch** (Airflow) ‚Üí **Lake Bronze (Parquet)**
2. Nettoyage/standardisation ‚Üí **Lake Silver (Delta/Iceberg)**
3. Mod√©lisation **√©toile** ‚Üí **EDW** (dbt)
4. **BI** sur EDW ; **ML** sur Lake Silver/Gold
5. **Gouvernance** : Catalog + Qualit√© + Lineage


</div>

---

### Architecture et conception

#### Conception de l‚Äôarchitecture Big Data


<div style="font-size:25px">

## 5) Blueprints d‚Äôarchitecture (r√©f√©rences rapides)

### 5.2 ‚ÄúStreaming-first‚Äù (√©v√©nementiel + lakehouse)

1. **CDC/√©v√©nements** ‚Üí **Kafka** (+ Schema Registry, DLQ)
2. **Structured Streaming (Spark)** ‚Üí **Delta/Iceberg** (UPSERT)
3. **Gold tables** (agr√©gats quasi-temps r√©el)
4. **BI live** (Trino/warehouse sur tables ACID) & **features** pour ML online
5. **Observabilit√©** : m√©triques pipeline, SLA fra√Æcheur, *data contracts*

</div>

---

## Architecture et conception

### Choix technologiques et gouvernance


<div style="font-size:35px">

<br>

Le succ√®s d‚Äôun projet Big Data d√©pend non seulement de l‚Äôarchitecture technique (collecte, stockage, traitement), mais aussi de **choix strat√©giques sur l‚Äôinfrastructure** et d‚Äôune **gouvernance solide** (s√©curit√©, conformit√©, ownership).

</div>

---

## Architecture et conception

### Choix technologiques et gouvernance


<div style="font-size:28px">


### 1Ô∏è‚É£ Cloud (AWS, Azure, GCP) vs On-premise

### üîπ Cloud Public (AWS, Azure, GCP)

**Avantages :**

* **√âlasticit√© & scalabilit√©** : ressources quasi illimit√©es, ajustables en temps r√©el.
* **Time-to-market rapide** : services manag√©s (pas de gestion de serveurs).
* **√âcosyst√®me riche** : IA, ML, BI int√©gr√©s (AWS SageMaker, Azure ML, BigQuery ML).
* **Pay-as-you-go** : paiement √† l‚Äôusage (CapEx ‚Üí OpEx).


</div>

---

## Architecture et conception

### Choix technologiques et gouvernance


<div style="font-size:28px">


### 1Ô∏è‚É£ Cloud (AWS, Azure, GCP) vs On-premise

### üîπ Cloud Public (AWS, Azure, GCP)

**Limites :**

* D√©pendance au fournisseur (**vendor lock-in**).
* Co√ªts parfois √©lev√©s si mauvaise gouvernance (data egress, ressources non √©teintes).
* Enjeux de **souverainet√©** (donn√©es sensibles, r√©glementations).


</div>

---

## Architecture et conception

### Choix technologiques et gouvernance


<div style="font-size:28px">


### 1Ô∏è‚É£ Cloud (AWS, Azure, GCP) vs On-premise

### üîπ Cloud Public (AWS, Azure, GCP)

**Exemples :**

* **AWS** : S3 (lac), EMR (Spark), Redshift (DW), Glue (ETL), Kinesis (streaming).
* **Azure** : Data Lake Storage, Synapse, Databricks, Event Hub, Purview (catalogue).
* **GCP** : BigQuery (DW serverless), Dataflow (streaming batch/stream), Pub/Sub, Vertex AI.

</div>

---

## Architecture et conception

### Choix technologiques et gouvernance


<div style="font-size:23px">


### 1Ô∏è‚É£ Cloud (AWS, Azure, GCP) vs On-premise

### üîπ On-premise (datacenters internes)

**Avantages :**

* **Ma√Ætrise compl√®te** des donn√©es (souverainet√©, conformit√© stricte).
* **Co√ªts fixes** : investissements mat√©riels amortis sur plusieurs ann√©es.
* **Flexibilit√©** dans le choix technologique (open source, architectures personnalis√©es).

**Limites :**

* **Capacit√© limit√©e** : n√©cessit√© d‚Äôanticiper les besoins.
* **Complexit√© op√©rationnelle** : maintenance mat√©rielle, mises √† jour, s√©curit√©.
* **Time-to-market plus long** (installation, param√©trage, √©quipes sp√©cialis√©es).


</div>

---

## Architecture et conception

### Choix technologiques et gouvernance


<div style="font-size:28px">


### 1Ô∏è‚É£ Cloud (AWS, Azure, GCP) vs On-premise

### üîπ On-premise (datacenters internes)

**Cas d‚Äôusage typiques :**

* Institutions financi√®res soumises √† r√©gulations strictes (banques centrales).
* Organisations publiques avec donn√©es classifi√©es.

</div>

---

### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:21px">


### 1Ô∏è‚É£ Cloud (AWS, Azure, GCP) vs On-premise

### üîπ Hybride & Multicloud

Souvent le **meilleur compromis** :

* **Hybride** : certaines donn√©es sensibles on-premise, autres dans le cloud.
* **Multicloud** : r√©partition des services (ex. GCP pour IA, AWS pour data lake, Azure pour BI).

**Exemples :**

* Banque : donn√©es clients sensibles on-premise, analyses comportementales dans le cloud.
* Industrie : usines avec stockage local (faible latence), mais consolidation dans un cloud central.

üëâ **Bonnes pratiques** :

* D√©finir une **politique de souverainet√©** (o√π stocker quoi).
* √âviter le lock-in ‚Üí favoriser standards (Kubernetes, Delta Lake, Kafka multi-cloud).
* Automatiser gouvernance via IaC (Terraform, Ansible).

</div>

---

### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:23px">


### 2Ô∏è‚É£ R√®gles de s√©curit√©, confidentialit√©, RGPD

#### üîπ S√©curit√© des donn√©es Big Data

* **Chiffrement** :

  * **At rest** (donn√©es stock√©es) ‚Üí KMS, cl√©s g√©r√©es par client (BYOK).
  * **In transit** (r√©seaux) ‚Üí TLS 1.2+, VPN, PrivateLink.
* **Contr√¥les d‚Äôacc√®s** :

  * RBAC (Role-Based Access Control),
  * ABAC (Attribute-Based Access Control, ex. tags ¬´ sensitive\:true ¬ª).
* **Audit & tra√ßabilit√©** : journalisation des acc√®s, alertes anomalies.
* **Segmentation r√©seau** : VPC, sous-r√©seaux priv√©s, firewalls.
</div>

---

### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:28px">


### 2Ô∏è‚É£ R√®gles de s√©curit√©, confidentialit√©, RGPD

#### üîπ Confidentialit√© & RGPD

* **Consentement** : les utilisateurs doivent accepter la collecte.
* **Minimisation** : ne collecter que les donn√©es n√©cessaires.
* **Droit √† l‚Äôoubli** : capacit√© de suppression/anonymisation des donn√©es.
* **Portabilit√©** : export des donn√©es utilisateur dans un format lisible (JSON, CSV).
* **Data masking / anonymisation** : pseudonymisation des identifiants, hashing des emails.
</div>

---

### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:23px">


### 2Ô∏è‚É£ R√®gles de s√©curit√©, confidentialit√©, RGPD

#### üîπ Cas d‚Äôusage s√©curit√©

* **Banque** : logs chiffr√©s en temps r√©el (Kafka + TLS + Kerberos).
* **E-commerce** : masquage des CB dans le Data Lake.
* **Sant√©** : anonymisation dossiers m√©dicaux pour l‚ÄôIA.

üëâ **Check-list s√©curit√© Big Data** :

* [ ] Chiffrement (stockage + transfert).
* [ ] Contr√¥les d‚Äôacc√®s granulaires.
* [ ] Journalisation des acc√®s.
* [ ] Politique RGPD document√©e.
* [ ] Anonymisation syst√©matique des donn√©es sensibles.

</div>

---

### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:23px">


### 3Ô∏è‚É£ Gouvernance des donn√©es : catalogue, qualit√©, ownership

#### üîπ Data Catalogue

* **Objectif** : permettre aux √©quipes de savoir **quelles donn√©es existent, o√π, avec quelle qualit√©**.
* **Fonctionnalit√©s cl√©s** :

  * Indexation automatique des datasets.
  * Recherche par mots-cl√©s, m√©tadonn√©es.
  * Lineage (tra√ßabilit√© : origine ‚Üí transformations ‚Üí usage).
  * Tagging (sensible, confidentiel, PII).
* **Outils** : Apache Atlas, AWS Glue Data Catalog, Azure Purview, Collibra, Alation.


</div>

---


### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:23px">


### 3Ô∏è‚É£ Gouvernance des donn√©es : catalogue, qualit√©, ownership

#### üîπ Qualit√© des donn√©es

* **Dimensions** : compl√©tude, coh√©rence, exactitude, unicit√©, fra√Æcheur.
* **Pratiques** :

  * Tests automatiques (Great Expectations, Deequ).
  * Alertes sur d√©rive (volumes anormaux, valeurs aberrantes).
  * Validation en amont (schema-on-write) ou en aval (schema-on-read).
* **Exemple** :

  * Retail : alerte si taux de remplissage email < 90 %.
  * IoT : alerte si capteurs renvoient 0 valeurs > 5 min.

</div>

---

### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:23px">


### 3Ô∏è‚É£ Gouvernance des donn√©es : catalogue, qualit√©, ownership

#### üîπ Ownership & gouvernance organisationnelle

* **Data Owner** (propri√©taire m√©tier) : responsable de la donn√©e, d√©finit r√®gles d‚Äôusage.
* **Data Steward** (r√©f√©rent qualit√©) : veille √† la qualit√©, applique standards.
* **Data Engineer** : impl√©mente pipelines, assure disponibilit√© technique.
* **Data Governance Committee** : arbitre les conflits, d√©finit normes globales.

**Bonnes pratiques organisationnelles** :

* Mettre en place un **Data Governance Board** (IT + m√©tier).
* Instaurer un **Data Catalog** obligatoire pour chaque nouveau dataset.
* D√©finir des **KPI qualit√©** : % de doublons, % de compl√©tude, % de fra√Æcheur < 24h.
* Documenter chaque jeu de donn√©es (m√©tadonn√©es minimales obligatoires).
</div>

---


### Architecture et conception

#### Choix technologiques et gouvernance


<div style="font-size:25px">


##  Synth√®se

| Domaine                  | Pratiques                                          | Outils/Technos                 | B√©n√©fices                                 |
| ------------------------ | -------------------------------------------------- | ------------------------------ | ----------------------------------------- |
| Infra : Cloud vs On-prem | Choix selon scalabilit√©, co√ªt, souverainet√©        | AWS/GCP/Azure, clusters Hadoop | Flexibilit√©, co√ªts ma√Ætris√©s              |
| S√©curit√© & RGPD          | Chiffrement, RBAC/ABAC, anonymisation, tra√ßabilit√© | KMS, TLS, Ranger, Kerberos     | Conformit√© l√©gale, confiance clients      |
| Gouvernance              | Catalogue, qualit√©, ownership, comit√© data         | Atlas, Glue, Purview, Collibra | Donn√©es fiables, accessibles, document√©es |

</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:28px">


#### 1) M√©thodes de gestion : Cycle en V vs Agile (Scrum, Kanban)

<br>

**Cycle en V (pr√©dictif)**

* Quand l‚Äôutiliser : exigences stables, conformit√© forte (banque, sant√©), d√©pendances lourdes (r√©seau, s√©curit√©), budget verrouill√©.
* Phases cl√©s : Cadrage ‚Üí Sp√©cifs ‚Üí Conception ‚Üí Build ‚Üí Tests ‚Üí Recette ‚Üí Mise en prod.
* * : tra√ßabilit√©, conformit√©, visibilit√© co√ªts/d√©lais.
* ‚àí : faible flexibilit√©, feedback tardif, risque d‚Äôeffet tunnel.


</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:27px">


#### 1) M√©thodes de gestion : Cycle en V vs Agile (Scrum, Kanban)

<br>

**Scrum (it√©ratif/incr√©mental)**

* Artefacts : Product Backlog, Sprint Backlog, Increment (d√©mo √† chaque fin de sprint).
* Rituels : Planning (objectif de sprint), Daily (15 min), Review (d√©mo m√©tier), Retrospective (am√©liorations).
* Quand l‚Äôutiliser : incertitude √©lev√©e (donn√©es/qualit√©, exploration ML), besoin de valeur fr√©quente (dashboards, features).
* Bonnes pratiques data : DoR/DoD orient√©es data (sch√©mas versionn√©s, tests DQ, validation de perf mod√®le, runbook mis √† jour).


</div>

---


### Architecture et conception

#### Organisation du projet


<div style="font-size:27px">


#### 1) M√©thodes de gestion : Cycle en V vs Agile (Scrum, Kanban)

<br>

**Kanban (flux tir√©)**

* Principes : visualiser le flux, limiter le WIP, mesurer & am√©liorer (lead/cycle time).
* Colonnes typiques data : Discovery ‚Üí Sourcing ‚Üí Transformation ‚Üí Validation DQ/QA ‚Üí D√©ploiement ‚Üí Monitoring.
* Id√©al pour : run, dataops, petites √©quipes pluridisciplinaires, flux de tickets (anomalies, petites √©volutions).

</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:30px">


#### 1) M√©thodes de gestion : Cycle en V vs Agile (Scrum, Kanban)

<br>

**Choisir vite**

* Forte incertitude/POC/ML ? ‚Üí Scrum.
* Flux de petites demandes & incidents ? ‚Üí Kanban.
* Projet r√©glement√© √† p√©rim√®tre fig√© ? ‚Üí V.
* Organisation ‚Äúplateforme + domaines‚Äù ? ‚Üí Scrum par domaine + Kanban pour la plateforme.

</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:23px">



### 2) R√¥les & responsabilit√©s (focus principaux)

**Product Owner (PO)**

* Mission : maximiser la valeur m√©tier, g√©rer la roadmap & le backlog, d√©finir l‚Äôacceptation.
* Livrables : Vision, OKR, user stories & crit√®res Gherkin, priorisation (Value/Effort, WSJF).
* KPI : time-to-value, adoption, NPS interne, objectifs produits atteints.

**Architecte (Data/Entreprise)**

* Mission : cible d‚Äôarchitecture, choix technos, normes (s√©curit√©, RGPD), co√ªts/fiabilit√©, interop√©rabilit√©.
* Livrables : diagrammes, ADR (decisions log), standards (naming, versioning), mod√®les de donn√©es, data contracts.
* KPI : disponibilit√©/capacit√©, co√ªts unitaires, conformit√©, dette technique.
</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:27px">


### 2) R√¥les & responsabilit√©s (focus principaux)

<br>

**Data Engineer (DE)**

* Mission : ingestion/ELT, qualit√© & fiabilit√© (tests, monitoring), CI/CD, MLOps/DatOps, performance & co√ªts.
* Livrables : pipelines, jobs, tests DQ, sch√©mas versionn√©s, orchs (DAG), runbooks/alertes.
* KPI : fra√Æcheur, taux d‚Äô√©chec des jobs, SLA/SLO, co√ªt/Go, MTTR.

</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:26px">


### 2) R√¥les & responsabilit√©s (focus principaux)

**Data Analyst (DA)**

* **Mission** : traduire les questions m√©tier en analyses actionnables, concevoir/maintenir les KPI, produire des insights fiables, √©vang√©liser la data aupr√®s des √©quipes (self-service & data literacy).
* **Livrables** : tableaux de bord & rapports (storytelling), requ√™tes SQL/notes d‚Äôanalyse reproductibles, d√©finitions de m√©triques (dictionnaire KPI + r√®gles de calcul), √©tudes ad-hoc & A/B tests, cahiers de besoins BI, guide d‚Äôusage des dashboards.
* **KPI** : adoption des tableaux de bord, time-to-insight (d√©lai demande‚Üír√©ponse), exactitude des KPI (√©carts vs ‚Äúsource of truth‚Äù), taux de self-service, taux d‚Äôanalyses menant √† une action business (features lanc√©es, co√ªts √©vit√©s, revenus incr√©mentaux).

</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:27px">


### 2) R√¥les & responsabilit√©s (focus principaux)

#### Qui fait quoi ?

* **Enterprise Architect** : fixe les **principes** et standards globaux (urbanisation SI, cloud strategy).
* **Data Architect** : **con√ßoit l‚Äôarchitecture data cible** (lakehouse, DWH, MDM, streaming, catalog, s√©curit√©, formats, SLA).
* **Solution Architect** : **assemble** les briques pour **un projet** donn√© (choix concrets, diagrammes solution).
* **Data Platform / Cloud Engineers** : **construisent la plateforme** (infra cloud, stockage, compute, IAM, r√©seau, catalog, jobs schedulers).

</div>

---

### Architecture et conception

#### Organisation du projet


<div style="font-size:23px">


### 2) R√¥les & responsabilit√©s (focus principaux)

#### Qui fait quoi ?


* **Data Engineers** : **d√©veloppent les pipelines** d‚Äôingestion & de transformation (batch/stream), tests DQ, contrats de donn√©es.
* **Analytics Engineers** : **mod√©lisent le couche analytique** (staging ‚Üí marts, semantic layer, tests dbt).
* **DBA/DBRE** : exploitent et optimisent les **bases/engines** (perfs, sauvegardes, r√©plication, RPO/RTO).
* **DataOps/SRE** : **observabilit√© & run** (SLI/SLO, alerting, fiabilit√©, MTTR).
* **Security/RSSI & DPO** : politiques **IAM, chiffrement, RGPD** (revues, audits).
* **Data Steward / Data Owner** : **gouvernance & qualit√©** (catalog, d√©finitions KPI, r√®gles DQ, propri√©taires).

</div>

---


### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:30px">

<br>

- Le **pilotage op√©rationnel** vise √† assurer que le projet **avance selon la feuille de route**, respecte les contraintes (temps, co√ªts, qualit√©) et atteint les **objectifs m√©tier**.
- Dans le contexte Big Data, il doit int√©grer la **complexit√© technologique**, la **qualit√© des donn√©es** et la **conduite du changement** c√¥t√© utilisateurs.

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:22px">

## 1Ô∏è‚É£ Roadmap, jalons, livrables

### üîπ Roadmap

La roadmap est une **vue globale et temporelle du projet**, structur√©e autour des grands objectifs m√©tier et techniques.

* D√©coup√©e en **phases** :

  1. **Cadrage** (besoin m√©tier, faisabilit√©, gouvernance)
  2. **Conception** (architecture, choix techno, s√©curit√©)
  3. **Impl√©mentation** (pipelines, stockage, traitements)
  4. **Validation** (tests, qualit√© donn√©es, POC ‚Üí pilote)
  5. **D√©ploiement** (production, monitoring, adoption)
  6. **Industrialisation & am√©lioration continue**

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:25px">

## 1Ô∏è‚É£ Roadmap, jalons, livrables

### üîπ Roadmap

**Exemple (6 mois)** :

* Mois 1 : cadrage, d√©finition cas d‚Äôusage, cartographie donn√©es
* Mois 2‚Äì3 : conception architecture + POC technique
* Mois 4 : d√©veloppement pipelines ingestion + stockage (zone Bronze/Silver)
* Mois 5 : premiers dashboards et mod√®les ML ‚Üí pilote
* Mois 6 : mise en production + formation utilisateurs


</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:25px">

## 1Ô∏è‚É£ Roadmap, jalons, livrables

### üîπ Jalons (milestones)

Les jalons sont des **points cl√©s de validation**.

* **Exemple Banque (fraude)** :

  * Jalon 1 : POC d√©tection temps r√©el valid√© (<2 s latence).
  * Jalon 2 : pipeline Kafka ‚Üí Data Lake op√©rationnel.
  * Jalon 3 : mod√®le ML int√©gr√© en scoring.
  * Jalon 4 : dashboards BI fraud management valid√©s par m√©tier.
  * Jalon 5 : mise en production s√©curis√©e.


</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:25px">

## 1Ô∏è‚É£ Roadmap, jalons, livrables

### üîπ Livrables

Chaque phase doit produire des **artefacts concrets** valid√©s.

* **Cadrage** : cahier de charges, business case, estimation ROI.
* **Conception** : sch√©ma d‚Äôarchitecture, RACI (r√¥les), plan s√©curit√©/RGPD.
* **Impl√©mentation** : pipelines ETL, data lake structur√©, scripts Terraform.
* **Validation** : rapports de tests, tableaux qualit√© donn√©es.
* **D√©ploiement** : dashboards BI, API ML, manuel utilisateur.
* **Industrialisation** : documentation, monitoring (Grafana/Prometheus), playbooks incident.

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:25px">

## 2Ô∏è‚É£ Indicateurs cl√©s (KPI)

Le pilotage doit s‚Äôappuyer sur des **indicateurs de suivi pr√©cis et mesurables**.

### üîπ Qualit√© des donn√©es

* **Compl√©tude** : % de champs remplis (objectif > 95%).
* **Exactitude** : √©cart tol√©r√© entre donn√©es sources et donn√©es trait√©es (<1%).
* **Fra√Æcheur** : d√©lai entre g√©n√©ration et disponibilit√© (ex. <5 min pour fraude, <24h pour reporting).
* **Taux d‚Äôanomalies d√©tect√©es** : donn√©es invalides, doublons, incoh√©rences.

üëâ *Exemple* : sur un projet IoT, 99% des capteurs doivent envoyer des donn√©es toutes les 5 minutes.

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:25px">

## 2Ô∏è‚É£ Indicateurs cl√©s (KPI)

Le pilotage doit s‚Äôappuyer sur des **indicateurs de suivi pr√©cis et mesurables**.

### üîπ Performance technique

* **Latence de traitement** : temps ingestion ‚Üí mise √† dispo (batch J+1 ou streaming <2 s).
* **D√©bit** : nombre d‚Äô√©v√©nements/s trait√©s (scalabilit√©).
* **Disponibilit√©** : SLA (ex. 99,9 % uptime du pipeline Kafka/Spark).
* **Temps de r√©ponse** : API de recommandation < 300 ms (p95).

üëâ *Exemple* : moteur de recommandation retail ‚Üí 95% des requ√™tes < 200 ms.

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:24px">

## 2Ô∏è‚É£ Indicateurs cl√©s (KPI)

### üîπ Adoption m√©tier

* **Taux d‚Äôutilisation des dashboards** : nombre de connexions hebdo / utilisateurs cibles.
* **Taux d‚Äôappropriation** : % de m√©tiers form√©s qui utilisent r√©ellement la solution.
* **Impact m√©tier** :

  * Banque : % fraudes d√©tect√©es suppl√©mentaires.
  * Retail : augmentation du panier moyen.
  * Industrie : r√©duction des arr√™ts machine.

üëâ *Exemple* : objectif 80% des managers logistique connect√©s chaque semaine au dashboard pr√©dictif.

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:23px">

## 3Ô∏è‚É£ Suivi budg√©taire et risques

### üîπ Suivi budg√©taire

* **CapEx (investissement initial)** : serveurs, licences, mise en place cloud.
* **OpEx (co√ªts r√©currents)** : stockage cloud (S3, ADLS), compute (Spark, EMR, Databricks), monitoring.
* **Ressources humaines** : Data Engineers, Data Scientists, formation.
* **Outils de suivi** :

  * Tableaux de bord financiers (mensuels).
  * Alertes budget cloud (AWS Budgets, Azure Cost Management, GCP Billing).

üëâ *Exemple* : seuil d‚Äôalerte si co√ªts cloud mensuels > +10% du pr√©visionnel.

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:20px">

## 3Ô∏è‚É£ Suivi budg√©taire et risques

### üîπ Gestion des risques

**Typologie des risques Big Data** :

1. **Techniques** :

   * Pipeline non scalable (Kafka satur√©).
   * D√©rive de sch√©ma ‚Üí job cass√©.
   * Donn√©es manquantes ‚Üí mod√®les biais√©s.
   * ‚Üí *Parade* : tests de charge, data contracts, monitoring qualit√©.

2. **Organisationnels** :

   * Manque de comp√©tences internes.
   * D√©pendance √† un seul fournisseur cloud (**vendor lock-in**).
   * ‚Üí *Parade* : formation, multicloud, adoption standards (Kubernetes, Delta Lake).

</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:20px">

## 3Ô∏è‚É£ Suivi budg√©taire et risques

### üîπ Gestion des risques

**Typologie des risques Big Data** :

3. **R√©glementaires et √©thiques** :

   * Non-conformit√© RGPD (donn√©es sensibles stock√©es sans consentement).
   * Biais algorithmiques (discrimination dans scoring cr√©dit).
   * ‚Üí *Parade* : DPO impliqu√©, audits, IA responsable (explicabilit√©).

4. **Adoption m√©tier** :

   * Outils livr√©s mais non utilis√©s.
   * M√©tiers non impliqu√©s dans conception.
   * ‚Üí *Parade* : ateliers r√©guliers, feedback utilisateurs, accompagnement au changement.


</div>

---

### Architecture et conception

#### Pilotage op√©rationnel d‚Äôun projet Big Data


<div style="font-size:20px">



| Dimension        | Bonnes pratiques                       | Exemple                                |
| ---------------- | -------------------------------------- | -------------------------------------- |
| Roadmap & jalons | D√©coupage phases + milestones clairs   | POC valid√© en 2 mois, pilote en 4 mois |
| Livrables        | Artefacts concrets valid√©s par sponsor | Sch√©ma archi, pipelines, dashboards    |
| KPI Qualit√©      | Compl√©tude, fra√Æcheur, anomalies       | Fra√Æcheur <5 min, exactitude 99%       |
| KPI Performance  | Latence, d√©bit, SLA                    | API reco <300 ms (p95)                 |
| KPI Adoption     | Usage r√©el, impact m√©tier              | 80% managers connect√©s/semaine         |
| Budget           | Suivi CapEx/OpEx + alertes cloud       | Alerte > +10% budget pr√©vu             |
| Risques          | Typologie + registre + mitigation      | Vendor lock-in ‚Üí multicloud            |

</div>

---

